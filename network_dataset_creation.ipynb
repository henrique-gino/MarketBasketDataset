{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ee56af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67601908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading demographic information, then creating income classes\n",
    "hh_feat = pd.read_csv('hh_demographic.csv')\n",
    "\n",
    "low_inc = ['Under 15K', '15-24K', '25-34K', '35-49K']\n",
    "mid_inc = ['50-74K', '75-99K', '100-124K', '125-149K']\n",
    "up_inc = ['150-174K', '175-199K', '200-249K', '250K+']\n",
    "\n",
    "def define_income(df):\n",
    "    if df['INCOME_DESC'] in low_inc:\n",
    "        return 'Low'\n",
    "    elif df['INCOME_DESC'] in mid_inc:\n",
    "        return 'Middle'\n",
    "    else:\n",
    "        return 'Upper'\n",
    "    \n",
    "hh_feat['family_income'] = hh_feat.apply(lambda x: define_income(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068463b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying primary descriptions of the most relevant products\n",
    "data = pd.read_csv('transaction_data.csv')\n",
    "data = data[data['QUANTITY'] != 0]\n",
    "data = data[data['SALES_VALUE'] != 0]\n",
    "\n",
    "products = pd.read_csv('product.csv')\n",
    "\n",
    "# If only grocery products are desired, then only_groc = 1\n",
    "only_groc = 0\n",
    "\n",
    "if only_groc == 1:\n",
    "    groc_products_only = products[products['DEPARTMENT'] == 'GROCERY']\n",
    "else:\n",
    "    groc_products_only = products\n",
    "\n",
    "data_filtered = data.merge(groc_products_only, on='PRODUCT_ID', how='inner')\n",
    "\n",
    "data_filtered['prod_price'] = pd.qcut(\n",
    "    data_filtered['SALES_VALUE'],\n",
    "    [0, .25, .5, .75, .9, 1],\n",
    "    labels=False\n",
    ")\n",
    "\n",
    "prim_desc_analysis = (\n",
    "    data_filtered\n",
    "    .groupby('COMMODITY_DESC')\n",
    "    .count()\n",
    "    .sort_values('PRODUCT_ID', ascending=False)\n",
    ")\n",
    "\n",
    "sec_desc_analysis = (\n",
    "    data_filtered\n",
    "    .groupby('SUB_COMMODITY_DESC')\n",
    "    .count()\n",
    "    .sort_values('PRODUCT_ID', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9363cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting most frequent prod_price from each product\n",
    "det_price = data_filtered.groupby(['PRODUCT_ID', 'prod_price', 'SALES_VALUE']).count()['DAY'].reset_index()\n",
    "det_price = det_price.groupby('PRODUCT_ID').first('prod_price')[['prod_price', 'SALES_VALUE']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1749710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating product dataframe\n",
    "groc_products = groc_products_only.merge(det_price, on='PRODUCT_ID') # price information\n",
    "groc_products['PRODUCT_ID'] = groc_products['PRODUCT_ID'].astype('str')\n",
    "\n",
    "groc_products = groc_products.rename(\n",
    "    {'COMMODITY_DESC': 'primary_description',\n",
    "    'SUB_COMMODITY_DESC': 'secondary_description'}, axis=1\n",
    ")\n",
    "\n",
    "groc_products_desc = groc_products[[\n",
    "    'PRODUCT_ID', 'primary_description', 'secondary_description', 'prod_price',\n",
    "    'DEPARTMENT', 'SALES_VALUE'\n",
    "]]\n",
    "\n",
    "groc_products_desc.to_csv('product_desc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0fd6bda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45329/2674493492.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['PRODUCT_ID'] = data['PRODUCT_ID'].astype('str')\n"
     ]
    }
   ],
   "source": [
    "# Getting only necessary columns from transactions data\n",
    "data = data_filtered[['household_key', 'BASKET_ID', 'DAY', 'PRODUCT_ID']]\n",
    "data['PRODUCT_ID'] = data['PRODUCT_ID'].astype('str')\n",
    "\n",
    "# Creating other demographic classes\n",
    "hh_feat = hh_feat.loc[hh_feat['HH_COMP_DESC'] != 'Unknown']\n",
    "kids_group = ['1 Adult Kids', '2 Adults Kids']\n",
    "hh_feat['has_kids'] = np.where(hh_feat['HH_COMP_DESC'].isin(kids_group), 1, 0)\n",
    "hh_feat = hh_feat.sample(frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc4fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactions(df, feature, demographic_value, file_name):\n",
    "    # df1: pd1 -> pd2 , user, user_features\n",
    "    df = df[['household_key', 'DAY', 'PRODUCT_ID', 'BASKET_ID']]\n",
    "\n",
    "    # Getting timeslice\n",
    "    df = df[(df['DAY']>365) & (df['DAY']<540)]\n",
    "\n",
    "    filter_prods = groc_products_desc\n",
    "    \n",
    "    # Filtering only interactions with desired products\n",
    "    df = (\n",
    "        df\n",
    "        .merge(filter_prods, on='PRODUCT_ID', how='inner')\n",
    "    )\n",
    "\n",
    "    df = df.drop(['prod_price', 'primary_description', 'secondary_description'], axis=1)\n",
    "\n",
    "    # Creating dataframe with combinations of products bought in the same basket\n",
    "    df_1 = df.rename(columns={'PRODUCT_ID': 'PRODUCT_ID_1'})\n",
    "    df = (\n",
    "        df_1\n",
    "        .merge(\n",
    "            df[['PRODUCT_ID', 'BASKET_ID']].rename(columns={'PRODUCT_ID': 'PRODUCT_ID_2'}),\n",
    "            on='BASKET_ID',\n",
    "            how='inner'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Removing duplicates from the combinatinos of products bought in the same basket\n",
    "    df['check_string'] = df.apply(\n",
    "        lambda row: ''.join(sorted([row['PRODUCT_ID_1'], row['PRODUCT_ID_2']])), axis=1\n",
    "    )\n",
    "    df = df.drop_duplicates(['BASKET_ID', 'check_string'])\n",
    "    df = df[df['PRODUCT_ID_1'] != df['PRODUCT_ID_2']]\n",
    "    prod_interactions = (\n",
    "        df\n",
    "        .drop_duplicates(subset=['DAY', 'PRODUCT_ID_1', 'PRODUCT_ID_2'])\n",
    "    )\n",
    "\n",
    "    prod_interactions = (\n",
    "        prod_interactions\n",
    "        .merge(\n",
    "            hh_feat[['household_key', feature]],\n",
    "            on='household_key',\n",
    "            how='inner'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Filtering interactions for desired demographic class\n",
    "    prod = prod_interactions[prod_interactions[feature]==demographic_value]\n",
    "\n",
    "    prod.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7dd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing interactions dataframes\n",
    "create_interactions(data, 'family_income', 'Low', 'interactions_low.csv')\n",
    "create_interactions(data, 'family_income', 'Middle', 'interactions_middle.csv')\n",
    "create_interactions(data, 'family_income', 'Upper', 'interactions_upper.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6da75532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to update the product_id column, replacing big numbers\n",
    "# from the original dataset with the product dataframe index. This is needed so\n",
    "# that we can use the networks in LargeNetVis\n",
    "def update_interactions(file_name):\n",
    "    # Reading interactions\n",
    "    df = pd.read_csv(file_name).drop(['SALES_VALUE', 'DEPARTMENT'], axis=1) #e.g., interactions_low.csv\n",
    "\n",
    "    # Updating PRODUCT_ID_1\n",
    "    prods = pd.read_csv('product_desc.csv')\n",
    "    prods['PRODUCT_ID_1'] = prods['PRODUCT_ID']\n",
    "    prods['PRODUCT_ID'] = prods.index\n",
    "    prods = prods.drop(['prod_price', 'SALES_VALUE', 'primary_description', 'secondary_description', 'DEPARTMENT'], axis=1)\n",
    "\n",
    "    df = df.merge(prods, on='PRODUCT_ID_1', how='inner')\n",
    "    df = df.drop('PRODUCT_ID_1', axis=1).rename(columns={'PRODUCT_ID': 'PRODUCT_ID_1'})\n",
    "\n",
    "    # Updating PRODUCT_ID_2\n",
    "    prods = pd.read_csv('product_desc.csv')\n",
    "    prods['PRODUCT_ID_2'] = prods['PRODUCT_ID']\n",
    "    prods['PRODUCT_ID'] = prods.index\n",
    "    prods = prods.drop(['prod_price', 'SALES_VALUE', 'primary_description', 'secondary_description', 'DEPARTMENT'], axis=1)\n",
    "\n",
    "    df = df.merge(prods, on='PRODUCT_ID_2', how='inner')\n",
    "    df = df.drop('PRODUCT_ID_2', axis=1).rename(columns={'PRODUCT_ID': 'PRODUCT_ID_2'})\n",
    "\n",
    "    df.to_csv(f'final_{file_name}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8923b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_interactions('interactions_upper.csv')\n",
    "update_interactions('interactions_middle.csv')\n",
    "update_interactions('interactions_low.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a212dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating product_desc\n",
    "prods = pd.read_csv('product_desc.csv')\n",
    "prods['PRODUCT_ID_2'] = prods['PRODUCT_ID']\n",
    "prods['PRODUCT_ID'] = prods.index\n",
    "prods = prods.drop('PRODUCT_ID_2', axis=1)\n",
    "\n",
    "prods.to_csv('final_product_desc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
